const express = require('express');
const puppeteer = require('puppeteer');
const archiver = require('archiver');
const fs = require('fs'); // <-- –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π fs –¥–ª—è createWriteStream
const fsPromises = require('fs').promises; // <-- –î–ª—è async/await –æ–ø–µ—Ä–∞—Ü–∏–π
const path = require('path');
const { URL } = require('url');

const app = express();
const PORT = process.env.PORT || 3000;

app.use(express.json());
app.use(express.static('.'));

// –•—Ä–∞–Ω–∏–ª–∏—â–µ –∑–∞–¥–∞—á
const jobs = {};

app.get('/', (req, res) => {
  res.sendFile(__dirname + '/index.html');
});

// –ó–∞–ø—É—Å–∫ –Ω–æ–≤–æ–π –∑–∞–¥–∞—á–∏
app.post('/start', async (req, res) => {
  const startUrl = req.body.url?.trim();
  const maxDepthInput = req.body.depth || '2';
  const maxDepth = Math.min(3, Math.max(1, parseInt(maxDepthInput)));

  if (!startUrl || !startUrl.startsWith('http')) {
    return res.status(400).send('‚ùå –£–∫–∞–∂–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π URL (–Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å http)');
  }

  const jobId = Date.now().toString(36);
  jobs[jobId] = { logs: ['üöÄ –ó–∞–¥–∞—á–∞ –∑–∞–ø—É—â–µ–Ω–∞...'], done: false, zipPath: null };
  res.json({ jobId });

  // –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –≤ —Ñ–æ–Ω–µ
  (async () => {
    try {
      await processSite(jobId, startUrl, maxDepth);
      jobs[jobId].done = true;
    } catch (err) {
      jobs[jobId].logs.push(`‚ùå –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞: ${err.message}`);
      jobs[jobId].done = true;
    }
  })();
});

// –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏
app.get('/status/:jobId', (req, res) => {
  const job = jobs[req.params.jobId];
  if (!job) {
    return res.status(404).json({ logs: ['‚ö†Ô∏è –ó–∞–¥–∞—á–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'], done: true });
  }
  res.json({ logs: job.logs, done: job.done });
});

// –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
app.get('/download/:jobId', async (req, res) => {
  const job = jobs[req.params.jobId];
  if (!job || !job.done || !job.zipPath) {
    return res.status(404).send('–ó–∞–¥–∞—á–∞ –Ω–µ –≥–æ—Ç–æ–≤–∞ –∏–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç');
  }
  res.download(job.zipPath, 'site-export.zip', async () => {
    // –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: —É–¥–∞–ª–∏ –ø–æ—Å–ª–µ –æ—Ç–¥–∞—á–∏
    try {
      await fsPromises.unlink(job.zipPath);
      await fsPromises.rm(path.dirname(job.zipPath), { recursive: true, force: true });
    } catch (e) {}
    delete jobs[req.params.jobId];
  });
});

// –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
async function processSite(jobId, startUrl, maxDepth) {
  const job = jobs[jobId];
  const normalizedUrl = new URL(startUrl).href;
  const baseUrl = new URL(normalizedUrl).origin;
  const visited = new Set();
  const queue = [{ url: normalizedUrl, depth: 0 }];
  const pdfDir = path.join(__dirname, `pdfs_${jobId}`);
  const zipPath = path.join(__dirname, `site-export_${jobId}.zip`);

  job.logs.push(`üåê –ë–∞–∑–æ–≤—ã–π URL: ${baseUrl}`);
  job.logs.push(`üß≠ –ì–ª—É–±–∏–Ω–∞ –æ–±—Ö–æ–¥–∞: ${maxDepth}`);

  try {
    await fsPromises.rm(pdfDir, { recursive: true, force: true });
    await fsPromises.mkdir(pdfDir, { recursive: true });

    const browser = await puppeteer.launch({
      headless: true,
      args: ['--no-sandbox', '--disable-setuid-sandbox', '--disable-dev-shm-usage']
    });
    const page = await browser.newPage();
    await page.setViewport({ width: 1280, height: 800 });

    while (queue.length > 0) {
      const { url, depth } = queue.shift();
      if (visited.has(url)) continue;
      if (!url.startsWith(baseUrl)) continue;

      visited.add(url);
      job.logs.push(`üì• [${depth}/${maxDepth}] ${url}`);

      try {
        await page.goto(url, { waitUntil: 'networkidle2', timeout: 15000 });

        let name = url
          .replace(baseUrl, '')
          .replace(/^\/|\/$/g, '')
          .replace(/\//g, '_')
          .replace(/[^a-z0-9_-]/gi, '_') || 'index';

        const pdfPath = path.join(pdfDir, `${name}.pdf`);
        await page.pdf({ path: pdfPath, format: 'A4', printBackground: true });
        job.logs.push(`‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: ${name}.pdf`);

        if (depth < maxDepth) {
          const links = await page.evaluate(() =>
            Array.from(document.querySelectorAll('a[href]'))
              .map(a => a.getAttribute('href'))
              .filter(href => href && !href.startsWith('#') && href.startsWith('/'))
          );
          for (const href of links) {
            try {
              const fullUrl = new URL(href, baseUrl).href;
              if (!visited.has(fullUrl)) {
                queue.push({ url: fullUrl, depth: depth + 1 });
              }
            } catch (e) {
              job.logs.push(`‚ö†Ô∏è –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Å—Å—ã–ª–∫–∞: ${href}`);
            }
          }
        }
      } catch (e) {
        job.logs.push(`‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ: ${url} ‚Äî ${e.message}`);
      }
    }

    await browser.close();

    // –°–æ–∑–¥–∞–Ω–∏–µ ZIP
    job.logs.push('üì¶ –°–æ–∑–¥–∞–Ω–∏–µ ZIP-–∞—Ä—Ö–∏–≤–∞...');
    const zipStream = fs.createWriteStream(zipPath); // <-- –ò—Å–ø–æ–ª—å–∑—É–µ–º fs, –∞ –Ω–µ fsPromises
    const archive = archiver('zip', { zlib: { level: 6 } });
    archive.pipe(zipStream);

    for (const file of await fsPromises.readdir(pdfDir)) {
      archive.file(path.join(pdfDir, file), { name: file });
    }

    await archive.finalize();
    await new Promise(resolve => zipStream.on('close', resolve));

    job.zipPath = zipPath;
    job.logs.push('‚úÖ ZIP –≥–æ—Ç–æ–≤.');
  } catch (err) {
    job.logs.push(`üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: ${err.message}`);
    throw err;
  }
}

app.listen(PORT, () => {
  console.log(`‚úÖ –°–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω: http://localhost:${PORT}`);
});
